{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meghanjali Chennupati (U30308400)\n",
    "\n",
    "### Question : \n",
    "\n",
    "Find or synthesize a JSON dataset.\n",
    "\n",
    "This should be stored in either a BSON or JSON file format\n",
    "\n",
    "Using a python notebook, do the following:\n",
    "\n",
    "Load the data into a MongoDB collection\n",
    "\n",
    "Demonstrate an aggregation query on the data\n",
    "\n",
    "Save the results from the query to either a JSON or BSON file format.\n",
    "\n",
    "Your notebook must discuss what it is you’re doing; like a report.\n",
    "\n",
    "i.e., When loading the data, discuss where the data was obtained (if you synthesized the data, then include the notebook that creates the data); and the structure of this data.\n",
    "\n",
    "i.e. When querying the data, discuss what it is you’re trying to find out about the data, and how the query works to get you this result.\n",
    "Submit your notebook, credentials.py, and any supporting files to Canvas.\n",
    "\n",
    "Your credentials.py must include your correct username and password for the database (so that we can review the database structure on MongoDB Atlas)\n",
    "\n",
    "NOTE: If you’re synthesizing the data, then be sure to include the notebook that creates the data. If you are reading data that you obtained, but sure to include this data along with a link to it's source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Finding the data set :\n",
    "\n",
    "For the assignmnet I am chhosing the IRIS dataset in json format file.\n",
    "\n",
    "The data set source link is :  https://www.kaggle.com/datasets/rtatman/iris-dataset-json-version\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading the data in to the Mongo db collection :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the json file in to python data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the JSON data from the file into a Python data structure\n",
    "with open('iris.json', \"r\") as json_file:\n",
    "    iris_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First record in the Iris dataset:\n",
      "{'sepalLength': 5.1, 'sepalWidth': 3.5, 'petalLength': 1.4, 'petalWidth': 0.2, 'species': 'setosa'}\n"
     ]
    }
   ],
   "source": [
    "print(\"First record in the Iris dataset:\")\n",
    "print(iris_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a connection to our mongo db instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import credentials\n",
    "\n",
    "connection_string = f\"mongodb+srv://{credentials.username}:{credentials.password}@cluster0.8fcyccu.mongodb.net/\"\n",
    "\n",
    "client = pymongo.MongoClient(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['Meghanjali_iris_asg_data'] # create a database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1ebdee63f00>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['megha_iris_collection'].insert_many(iris_data) # creating a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=db['megha_iris_collection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Summary \n",
    "\n",
    "Till now I have read my json file for the iris data set and then I have creaed a connection to my mongo db instance I have loaded my iris ata set in to my mongodb collection.\n",
    "\n",
    "It got loaded in to the mongodb instance sucessfully.\n",
    "\n",
    "Coming to the description of the data . \n",
    "\n",
    "The data set source I uploaded the link . I downlaoded the json version for my iris data set.\n",
    "\n",
    "The data is actually structured data set. It contains the sepal lengh petal length sepal width petal width and species values .\n",
    "\n",
    "As we know Mongo db is acid compliance no sql data base it is properly handling my data set.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will perform some aggregation queries on my data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        u\"$group\": {\n",
    "            u\"_id\": {\n",
    "                u\"species\": u\"$species\"\n",
    "            },\n",
    "            u\"AVG(sepalLength)\": {\n",
    "                u\"$avg\": u\"$sepalLength\"\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        u\"$project\": {\n",
    "            u\"species\": u\"$_id.species\",\n",
    "            u\"AVG(sepalLength)\": u\"$AVG(sepalLength)\",\n",
    "            u\"_id\": 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "cursor = collection.aggregate(\n",
    "    pipeline, \n",
    "    allowDiskUse = True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bson.json_util as bju\n",
    "\n",
    "fin = open(\"final.json\", \"w\")\n",
    "fin.write(bju.dumps(list(cursor), indent=2))\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Organizations (USF)\n",
    "  - Projects (Projects 0)\n",
    "    - Clusters (Cluster 0)\n",
    "      - Databases (Meghanjali_iris_asg_data)\n",
    "        - Collections (megha_iris_collection)\n",
    "          - Documents (iris_data)\n",
    "            - Fields (sepal length, petal length, sepal width, petal width, species)\n",
    "              - Values (float, float, float, float, string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "1. I have extracted the aggrgation query of finding the average sepal length for each of my species .\n",
    "\n",
    "2. Iam storing the reulst to  a json file.\n",
    "\n",
    "3. The above code is dumping my data to the json file.\n",
    "\n",
    "4. Working of query : Firtsly grouping is applied on species and then average is the method applying on the sepal length column and then It is filteirng by speices and giving the reuslt.\n",
    "5. The data set which i get downlaoded from kaggle set I uplaoded the link and also I stored in iris_Data object in variable.\n",
    "6. As per the question I loaded aggrgated and save the reuslts and included the data set source and demonstration structure of the data set.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
